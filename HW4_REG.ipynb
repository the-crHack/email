{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-crHack/email/blob/main/HW4_REG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install unzip\n",
        "!pip install py_midicsv==4.1.2\n",
        "!pip install midi_player==0.5.1\n",
        "!unzip /content/sample_data/train-20241205T181153Z-001.zip -d /content/sample_data\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import random\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "bS9t-53Stzc6",
        "outputId": "df4c8c75-2df9-462a-d39b-6e13ef4c2cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting py_midicsv==4.1.2\n",
            "  Downloading py_midicsv-4.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting rich-click<2.0.0,>=1.8.3 (from py_midicsv==4.1.2)\n",
            "  Downloading rich_click-1.8.5-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: click>=7 in /usr/local/lib/python3.10/dist-packages (from rich-click<2.0.0,>=1.8.3->py_midicsv==4.1.2) (8.1.7)\n",
            "Requirement already satisfied: rich>=10.7 in /usr/local/lib/python3.10/dist-packages (from rich-click<2.0.0,>=1.8.3->py_midicsv==4.1.2) (13.9.4)\n",
            "Requirement already satisfied: typing_extensions>=4 in /usr/local/lib/python3.10/dist-packages (from rich-click<2.0.0,>=1.8.3->py_midicsv==4.1.2) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7->rich-click<2.0.0,>=1.8.3->py_midicsv==4.1.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.7->rich-click<2.0.0,>=1.8.3->py_midicsv==4.1.2) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.7->rich-click<2.0.0,>=1.8.3->py_midicsv==4.1.2) (0.1.2)\n",
            "Downloading py_midicsv-4.1.2-py3-none-any.whl (16 kB)\n",
            "Downloading rich_click-1.8.5-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: rich-click, py_midicsv\n",
            "Successfully installed py_midicsv-4.1.2 rich-click-1.8.5\n",
            "Collecting midi_player==0.5.1\n",
            "  Downloading midi_player-0.5.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Downloading midi_player-0.5.1-py3-none-any.whl (6.4 kB)\n",
            "Installing collected packages: midi_player\n",
            "Successfully installed midi_player-0.5.1\n",
            "Archive:  /content/sample_data/train-20241205T181153Z-001.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/sample_data/train-20241205T181153Z-001.zip or\n",
            "        /content/sample_data/train-20241205T181153Z-001.zip.zip, and cannot find /content/sample_data/train-20241205T181153Z-001.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) To ensure an adequate and diverse dataset, we extracted multiple overlapping context windows from each song with the following considerations:\n",
        "\n",
        "I used Multiple Instances Per Song to better capture the variations in musical patterns. This approach avoided under-utilizing the available data. I used a stride of 4 to avoid overlapping windows, increasing the effective dataset size.I limited max_samples_per_song to ensure that no single song dominated the dataset due to repeated patterns.\n",
        "Random Sampling: Random sampling of context windows ensured diversity in the extracted data, making the dataset more robust."
      ],
      "metadata": {
        "id": "ojn0G-hSOosJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/sample_data/train-20241205T181153Z-001.zip -d /content/sample_data"
      ],
      "metadata": {
        "id": "z-LCTUXguX0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Dataset Definition ---\n",
        "\n",
        "class SongsDataset(Dataset):\n",
        "    def __init__(self, files, context_window=64, max_samples_per_song=250):\n",
        "        self.data = []  # List to store input sequences (X)\n",
        "        self.labels = []  # List to store corresponding labels (Y)\n",
        "\n",
        "        # Iterate over each song file\n",
        "        for file in files:\n",
        "            # Load the song data (assuming it's stored as a tensor)\n",
        "            song_data = torch.load(file)  # song_data should be a tensor with shape (num_events, 4)\n",
        "\n",
        "            # Calculate dynamic stride based on the length of the song\n",
        "            stride = 4 #max(4, len(song_data) // 300)  # dynamic stride (longer songs get smaller strides)\n",
        "\n",
        "            # Create indices for sliding window with dynamic stride and sampling\n",
        "            indices = range(0, len(song_data) - context_window, stride)\n",
        "\n",
        "            # Sample a few indices for training (to avoid memory overload)\n",
        "            sampled_indices = random.sample(list(indices), min(max_samples_per_song, len(indices)))\n",
        "\n",
        "            # Extract data slices and labels\n",
        "            for i in sampled_indices:\n",
        "                # Input sequence: slice of notes with size `context_window`\n",
        "                self.data.append(song_data[i:i + context_window])  # Shape: (context_window, 4)\n",
        "                # Label: the next note after the context window\n",
        "                self.labels.append(song_data[i + context_window])  # Shape: (1, 4)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "\n",
        "# --- Model Definition ---\n",
        "\n",
        "class NotePredictionModel(nn.Module):\n",
        "    def __init__(self, dropout=0.2):\n",
        "        super(NotePredictionModel, self).__init__()\n",
        "\n",
        "        # LSTM Layer\n",
        "        self.lstm = nn.LSTM(input_size=4, hidden_size=128, batch_first=True, dropout=dropout)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(128, 134)  # We predict 134 values: [µ_t, σ_t, µ_d, σ_d, log(π0), ..., log(π127), µ_v, σ_v]\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTM layer with dropout\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "        last_output = lstm_out[:, -1, :]  # (batch_size, hidden_size)\n",
        "\n",
        "        # Apply dropout for regularization\n",
        "        last_output = self.dropout(last_output)\n",
        "\n",
        "        # Fully connected layer to predict the required values\n",
        "        output = self.fc(last_output)  # Shape: (batch_size, 134)\n",
        "\n",
        "        # Split the output into the predicted values\n",
        "        µ_t, σ_t, µ_d, σ_d, logits_n, µ_v, σ_v = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "\n",
        "        # Return the predicted values\n",
        "        return torch.cat((µ_t, σ_t, µ_d, σ_d, logits_n, µ_v, σ_v), dim=-1)\n",
        "\n",
        "\n",
        "# --- Loss Function ---\n",
        "\n",
        "def nll_loss_continuous(pred_mu, pred_sigma, target):\n",
        "    epsilon = 1e-6\n",
        "    pred_sigma = torch.max(pred_sigma, torch.tensor(epsilon))  # Prevent log(0)\n",
        "\n",
        "    loss = 0.5 * torch.log(2 * torch.tensor(torch.pi)) + torch.log(pred_sigma) + (target - pred_mu) ** 2 / (2 * pred_sigma ** 2)\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "# --- Training Function ---\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs, learning_rate, scheduler=None):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(12):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for step, (context, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(context)\n",
        "\n",
        "            # Split the output into predicted values\n",
        "            µ_t_pred, σ_t_pred, µ_d_pred, σ_d_pred, logits_n_pred, µ_v_pred, σ_v_pred = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "            logits_n_pred = F.softmax(logits_n_pred, dim=-1)\n",
        "\n",
        "            # Calculate the loss for continuous distributions using NLL\n",
        "            t_loss = nll_loss_continuous(µ_t_pred, σ_t_pred, target[:, 0])\n",
        "            d_loss = nll_loss_continuous(µ_d_pred, σ_d_pred, target[:, 1])\n",
        "            v_loss = nll_loss_continuous(µ_v_pred, σ_v_pred, target[:, 2])\n",
        "\n",
        "            # Calculate the categorical cross entropy for the note value logits\n",
        "            nll_loss = nn.CrossEntropyLoss()(logits_n_pred, target[:, 3].long())\n",
        "\n",
        "            # Total loss\n",
        "            loss = t_loss + d_loss + v_loss + nll_loss\n",
        "\n",
        "            if step % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Step {step}/{len(train_loader)}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize the model\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Log training loss\n",
        "        training_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Validate after every epoch\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for context, target in val_loader:\n",
        "                output = model(context)\n",
        "                µ_t_pred, σ_t_pred, µ_d_pred, σ_d_pred, logits_n_pred, µ_v_pred, σ_v_pred = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "                logits_n_pred = F.softmax(logits_n_pred, dim=-1)\n",
        "\n",
        "                # Calculate the loss for validation\n",
        "                t_loss = nll_loss_continuous(µ_t_pred, σ_t_pred, target[:, 0])\n",
        "                d_loss = nll_loss_continuous(µ_d_pred, σ_d_pred, target[:, 1])\n",
        "                v_loss = nll_loss_continuous(µ_v_pred, σ_v_pred, target[:, 2])\n",
        "\n",
        "                nll_loss = nn.CrossEntropyLoss()(logits_n_pred, target[:, 3].long())\n",
        "                val_loss += t_loss + d_loss + v_loss + nll_loss\n",
        "\n",
        "        validation_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "    return training_losses, validation_losses\n",
        "\n",
        "\n",
        "# --- Dataset Preparation ---\n",
        "\n",
        "# Example of file list with paths (you need to replace these with actual paths)\n",
        "train_files = glob.glob(\"/content/sample_data/train/*/*/*/*.pt\")  # Replace with your actual data files\n",
        "\n",
        "# Initialize the dataset\n",
        "context_window = 64  # Size of the context window\n",
        "max_samples_per_song = 250  # Max samples per song\n",
        "\n",
        "dataset = SongsDataset(train_files, context_window=context_window, max_samples_per_song=max_samples_per_song)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "val_size = len(dataset) - train_size  # 20% for validation\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader for training and validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# --- Model Initialization and Training ---\n",
        "\n",
        "# Initialize the model\n",
        "model = NotePredictionModel(dropout=0.3)  # Adding dropout for regularization\n",
        "\n",
        "# Train the model\n",
        "training_losses, validation_losses = train_model(model, train_loader, val_loader, epochs=12, learning_rate=0.01)\n",
        "\n",
        "# --- Plotting the Training and Validation Loss ---\n",
        "\n",
        "plt.plot(training_losses, label='Training Loss')\n",
        "plt.plot(validation_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a1I8jqEutx2b",
        "outputId": "65ca76e7-2bd3-4856-c117-7bc73cf28394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-648fc0fc6f1b>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  song_data = torch.load(file)  # song_data should be a tensor with shape (num_events, 4)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\n",
            "<ipython-input-4-648fc0fc6f1b>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12, Step 0/2391, Loss: 3.8997766176768e+16\n",
            "Epoch 1/12, Step 100/2391, Loss: 4597.6943359375\n",
            "Epoch 1/12, Step 200/2391, Loss: 1992.455078125\n",
            "Epoch 1/12, Step 300/2391, Loss: 4134.08203125\n",
            "Epoch 1/12, Step 400/2391, Loss: 2098.338134765625\n",
            "Epoch 1/12, Step 500/2391, Loss: 2105.70263671875\n",
            "Epoch 1/12, Step 600/2391, Loss: 3364.2822265625\n",
            "Epoch 1/12, Step 700/2391, Loss: 2555.210205078125\n",
            "Epoch 1/12, Step 800/2391, Loss: 4631.392578125\n",
            "Epoch 1/12, Step 900/2391, Loss: 1154.1571044921875\n",
            "Epoch 1/12, Step 1000/2391, Loss: 16236.0126953125\n",
            "Epoch 1/12, Step 1100/2391, Loss: 583.235107421875\n",
            "Epoch 1/12, Step 1200/2391, Loss: 1064.77587890625\n",
            "Epoch 1/12, Step 1300/2391, Loss: 1044.274658203125\n",
            "Epoch 1/12, Step 1400/2391, Loss: 373.1807861328125\n",
            "Epoch 1/12, Step 1500/2391, Loss: 468.5412292480469\n",
            "Epoch 1/12, Step 1600/2391, Loss: 1352.0775146484375\n",
            "Epoch 1/12, Step 1700/2391, Loss: 867.3375854492188\n",
            "Epoch 1/12, Step 1800/2391, Loss: 1286.4000244140625\n",
            "Epoch 1/12, Step 1900/2391, Loss: 648.7273559570312\n",
            "Epoch 1/12, Step 2000/2391, Loss: 369.7620544433594\n",
            "Epoch 1/12, Step 2100/2391, Loss: 1049.727294921875\n",
            "Epoch 1/12, Step 2200/2391, Loss: 1234.24609375\n",
            "Epoch 1/12, Step 2300/2391, Loss: 571.8855590820312\n",
            "Epoch [1/12], Training Loss: 17647191219950.2, Validation Loss: 539.755859375\n",
            "Epoch 2/12, Step 0/2391, Loss: 860.714111328125\n",
            "Epoch 2/12, Step 100/2391, Loss: 716.473388671875\n",
            "Epoch 2/12, Step 200/2391, Loss: 413.974853515625\n",
            "Epoch 2/12, Step 300/2391, Loss: 256.49658203125\n",
            "Epoch 2/12, Step 400/2391, Loss: 808.1461181640625\n",
            "Epoch 2/12, Step 500/2391, Loss: 612.7517700195312\n",
            "Epoch 2/12, Step 600/2391, Loss: 372.9654541015625\n",
            "Epoch 2/12, Step 700/2391, Loss: 553.4667358398438\n",
            "Epoch 2/12, Step 800/2391, Loss: 647.4901123046875\n",
            "Epoch 2/12, Step 900/2391, Loss: 363.83331298828125\n",
            "Epoch 2/12, Step 1000/2391, Loss: 829.0408325195312\n",
            "Epoch 2/12, Step 1100/2391, Loss: 599.9398803710938\n",
            "Epoch 2/12, Step 1200/2391, Loss: 231.9815216064453\n",
            "Epoch 2/12, Step 1300/2391, Loss: 515.7636108398438\n",
            "Epoch 2/12, Step 1400/2391, Loss: 420.1636047363281\n",
            "Epoch 2/12, Step 1500/2391, Loss: 406.22332763671875\n",
            "Epoch 2/12, Step 1600/2391, Loss: 258.95037841796875\n",
            "Epoch 2/12, Step 1700/2391, Loss: 133.70811462402344\n",
            "Epoch 2/12, Step 1800/2391, Loss: 347.76409912109375\n",
            "Epoch 2/12, Step 1900/2391, Loss: 139.5423583984375\n",
            "Epoch 2/12, Step 2000/2391, Loss: 214.2572021484375\n",
            "Epoch 2/12, Step 2100/2391, Loss: 399.308837890625\n",
            "Epoch 2/12, Step 2200/2391, Loss: 758.3766479492188\n",
            "Epoch 2/12, Step 2300/2391, Loss: 264.447998046875\n",
            "Epoch [2/12], Training Loss: 559.5419872384448, Validation Loss: 243.7816162109375\n",
            "Epoch 3/12, Step 0/2391, Loss: 696.6409912109375\n",
            "Epoch 3/12, Step 100/2391, Loss: 736.2005004882812\n",
            "Epoch 3/12, Step 200/2391, Loss: 400.0384216308594\n",
            "Epoch 3/12, Step 300/2391, Loss: 126.23075103759766\n",
            "Epoch 3/12, Step 400/2391, Loss: 293.99139404296875\n",
            "Epoch 3/12, Step 500/2391, Loss: 179.40792846679688\n",
            "Epoch 3/12, Step 600/2391, Loss: 453.26104736328125\n",
            "Epoch 3/12, Step 700/2391, Loss: 509.40460205078125\n",
            "Epoch 3/12, Step 800/2391, Loss: 94.23819732666016\n",
            "Epoch 3/12, Step 900/2391, Loss: 723.0177612304688\n",
            "Epoch 3/12, Step 1000/2391, Loss: 153.9918212890625\n",
            "Epoch 3/12, Step 1100/2391, Loss: 232.20701599121094\n",
            "Epoch 3/12, Step 1200/2391, Loss: 363.9637145996094\n",
            "Epoch 3/12, Step 1300/2391, Loss: 176.2530517578125\n",
            "Epoch 3/12, Step 1400/2391, Loss: 118.3935775756836\n",
            "Epoch 3/12, Step 1500/2391, Loss: 158.3231964111328\n",
            "Epoch 3/12, Step 1600/2391, Loss: 158.11317443847656\n",
            "Epoch 3/12, Step 1700/2391, Loss: 225.40948486328125\n",
            "Epoch 3/12, Step 1800/2391, Loss: 196.01112365722656\n",
            "Epoch 3/12, Step 1900/2391, Loss: 216.69749450683594\n",
            "Epoch 3/12, Step 2000/2391, Loss: 168.98947143554688\n",
            "Epoch 3/12, Step 2100/2391, Loss: 318.9468078613281\n",
            "Epoch 3/12, Step 2200/2391, Loss: 189.22787475585938\n",
            "Epoch 3/12, Step 2300/2391, Loss: 122.74134826660156\n",
            "Epoch [3/12], Training Loss: 283.6737754451635, Validation Loss: 134.32211303710938\n",
            "Epoch 4/12, Step 0/2391, Loss: 70.68586730957031\n",
            "Epoch 4/12, Step 100/2391, Loss: 282.5612487792969\n",
            "Epoch 4/12, Step 200/2391, Loss: 160.9745330810547\n",
            "Epoch 4/12, Step 300/2391, Loss: 138.2654266357422\n",
            "Epoch 4/12, Step 400/2391, Loss: 91.72515869140625\n",
            "Epoch 4/12, Step 500/2391, Loss: 278.1350402832031\n",
            "Epoch 4/12, Step 600/2391, Loss: 256.721923828125\n",
            "Epoch 4/12, Step 700/2391, Loss: 67.02599334716797\n",
            "Epoch 4/12, Step 800/2391, Loss: 135.18695068359375\n",
            "Epoch 4/12, Step 900/2391, Loss: 203.18597412109375\n",
            "Epoch 4/12, Step 1000/2391, Loss: 207.77244567871094\n",
            "Epoch 4/12, Step 1100/2391, Loss: 65.19734191894531\n",
            "Epoch 4/12, Step 1200/2391, Loss: 109.2684555053711\n",
            "Epoch 4/12, Step 1300/2391, Loss: 364.5626525878906\n",
            "Epoch 4/12, Step 1400/2391, Loss: 81.84136962890625\n",
            "Epoch 4/12, Step 1500/2391, Loss: 150.5252685546875\n",
            "Epoch 4/12, Step 1600/2391, Loss: 100.95228576660156\n",
            "Epoch 4/12, Step 1700/2391, Loss: 162.5088348388672\n",
            "Epoch 4/12, Step 1800/2391, Loss: 73.12493896484375\n",
            "Epoch 4/12, Step 1900/2391, Loss: 154.49151611328125\n",
            "Epoch 4/12, Step 2000/2391, Loss: 96.61485290527344\n",
            "Epoch 4/12, Step 2100/2391, Loss: 67.23167419433594\n",
            "Epoch 4/12, Step 2200/2391, Loss: 105.400146484375\n",
            "Epoch 4/12, Step 2300/2391, Loss: 90.49583435058594\n",
            "Epoch [4/12], Training Loss: 160.6008448566866, Validation Loss: 82.24307250976562\n",
            "Epoch 5/12, Step 0/2391, Loss: 355.86541748046875\n",
            "Epoch 5/12, Step 100/2391, Loss: 117.93733978271484\n",
            "Epoch 5/12, Step 200/2391, Loss: 71.45616912841797\n",
            "Epoch 5/12, Step 300/2391, Loss: 49.61553955078125\n",
            "Epoch 5/12, Step 400/2391, Loss: 123.75894165039062\n",
            "Epoch 5/12, Step 500/2391, Loss: 176.63829040527344\n",
            "Epoch 5/12, Step 600/2391, Loss: 68.66683959960938\n",
            "Epoch 5/12, Step 700/2391, Loss: 186.2096405029297\n",
            "Epoch 5/12, Step 800/2391, Loss: 39.87262725830078\n",
            "Epoch 5/12, Step 900/2391, Loss: 80.47206115722656\n",
            "Epoch 5/12, Step 1000/2391, Loss: 106.11688232421875\n",
            "Epoch 5/12, Step 1100/2391, Loss: 96.85552978515625\n",
            "Epoch 5/12, Step 1200/2391, Loss: 85.60835266113281\n",
            "Epoch 5/12, Step 1300/2391, Loss: 57.2868766784668\n",
            "Epoch 5/12, Step 1400/2391, Loss: 58.3658561706543\n",
            "Epoch 5/12, Step 1500/2391, Loss: 65.29769134521484\n",
            "Epoch 5/12, Step 1600/2391, Loss: 116.58293151855469\n",
            "Epoch 5/12, Step 1700/2391, Loss: 196.13510131835938\n",
            "Epoch 5/12, Step 1800/2391, Loss: 64.89262390136719\n",
            "Epoch 5/12, Step 1900/2391, Loss: 50.07688903808594\n",
            "Epoch 5/12, Step 2000/2391, Loss: 53.20591735839844\n",
            "Epoch 5/12, Step 2100/2391, Loss: 40.43080139160156\n",
            "Epoch 5/12, Step 2200/2391, Loss: 63.68635177612305\n",
            "Epoch 5/12, Step 2300/2391, Loss: 72.6668472290039\n",
            "Epoch [5/12], Training Loss: 98.57265759750871, Validation Loss: 54.879703521728516\n",
            "Epoch 6/12, Step 0/2391, Loss: 80.92774200439453\n",
            "Epoch 6/12, Step 100/2391, Loss: 52.619571685791016\n",
            "Epoch 6/12, Step 200/2391, Loss: 133.4259796142578\n",
            "Epoch 6/12, Step 300/2391, Loss: 44.379676818847656\n",
            "Epoch 6/12, Step 400/2391, Loss: 63.62141799926758\n",
            "Epoch 6/12, Step 500/2391, Loss: 39.663272857666016\n",
            "Epoch 6/12, Step 600/2391, Loss: 77.90974426269531\n",
            "Epoch 6/12, Step 700/2391, Loss: 55.543212890625\n",
            "Epoch 6/12, Step 800/2391, Loss: 50.78024673461914\n",
            "Epoch 6/12, Step 900/2391, Loss: 45.334983825683594\n",
            "Epoch 6/12, Step 1000/2391, Loss: 38.14085006713867\n",
            "Epoch 6/12, Step 1100/2391, Loss: 51.28654479980469\n",
            "Epoch 6/12, Step 1200/2391, Loss: 65.12560272216797\n",
            "Epoch 6/12, Step 1300/2391, Loss: 75.03815460205078\n",
            "Epoch 6/12, Step 1400/2391, Loss: 50.238346099853516\n",
            "Epoch 6/12, Step 1500/2391, Loss: 43.396034240722656\n",
            "Epoch 6/12, Step 1600/2391, Loss: 53.939720153808594\n",
            "Epoch 6/12, Step 1700/2391, Loss: 43.565330505371094\n",
            "Epoch 6/12, Step 1800/2391, Loss: 42.21533203125\n",
            "Epoch 6/12, Step 1900/2391, Loss: 42.792484283447266\n",
            "Epoch 6/12, Step 2000/2391, Loss: 38.2501220703125\n",
            "Epoch 6/12, Step 2100/2391, Loss: 43.50004959106445\n",
            "Epoch 6/12, Step 2200/2391, Loss: 40.486019134521484\n",
            "Epoch 6/12, Step 2300/2391, Loss: 44.61894989013672\n",
            "Epoch [6/12], Training Loss: 64.41888534469318, Validation Loss: 40.36293029785156\n",
            "Epoch 7/12, Step 0/2391, Loss: 60.785438537597656\n",
            "Epoch 7/12, Step 100/2391, Loss: 29.90911865234375\n",
            "Epoch 7/12, Step 200/2391, Loss: 36.317283630371094\n",
            "Epoch 7/12, Step 300/2391, Loss: 61.252655029296875\n",
            "Epoch 7/12, Step 400/2391, Loss: 65.11663818359375\n",
            "Epoch 7/12, Step 500/2391, Loss: 28.93442153930664\n",
            "Epoch 7/12, Step 600/2391, Loss: 45.6441535949707\n",
            "Epoch 7/12, Step 700/2391, Loss: 34.551063537597656\n",
            "Epoch 7/12, Step 800/2391, Loss: 33.19670867919922\n",
            "Epoch 7/12, Step 900/2391, Loss: 39.00021743774414\n",
            "Epoch 7/12, Step 1000/2391, Loss: 38.22673034667969\n",
            "Epoch 7/12, Step 1100/2391, Loss: 28.85521125793457\n",
            "Epoch 7/12, Step 1200/2391, Loss: 46.561370849609375\n",
            "Epoch 7/12, Step 1300/2391, Loss: 35.894676208496094\n",
            "Epoch 7/12, Step 1400/2391, Loss: 35.53937530517578\n",
            "Epoch 7/12, Step 1500/2391, Loss: 50.41609573364258\n",
            "Epoch 7/12, Step 1600/2391, Loss: 36.087371826171875\n",
            "Epoch 7/12, Step 1700/2391, Loss: 56.490020751953125\n",
            "Epoch 7/12, Step 1800/2391, Loss: 33.547088623046875\n",
            "Epoch 7/12, Step 1900/2391, Loss: 29.874794006347656\n",
            "Epoch 7/12, Step 2000/2391, Loss: 29.600950241088867\n",
            "Epoch 7/12, Step 2100/2391, Loss: 58.27145767211914\n",
            "Epoch 7/12, Step 2200/2391, Loss: 28.22552490234375\n",
            "Epoch 7/12, Step 2300/2391, Loss: 41.2786750793457\n",
            "Epoch [7/12], Training Loss: 46.060130056702704, Validation Loss: 32.886661529541016\n",
            "Epoch 8/12, Step 0/2391, Loss: 47.05615234375\n",
            "Epoch 8/12, Step 100/2391, Loss: 35.689125061035156\n",
            "Epoch 8/12, Step 200/2391, Loss: 37.14512252807617\n",
            "Epoch 8/12, Step 300/2391, Loss: 32.6816520690918\n",
            "Epoch 8/12, Step 400/2391, Loss: 29.64794158935547\n",
            "Epoch 8/12, Step 500/2391, Loss: 34.24674606323242\n",
            "Epoch 8/12, Step 600/2391, Loss: 35.56846618652344\n",
            "Epoch 8/12, Step 700/2391, Loss: 33.83857727050781\n",
            "Epoch 8/12, Step 800/2391, Loss: 27.623498916625977\n",
            "Epoch 8/12, Step 900/2391, Loss: 26.568603515625\n",
            "Epoch 8/12, Step 1000/2391, Loss: 35.38044738769531\n",
            "Epoch 8/12, Step 1100/2391, Loss: 42.52976608276367\n",
            "Epoch 8/12, Step 1200/2391, Loss: 37.916847229003906\n",
            "Epoch 8/12, Step 1300/2391, Loss: 34.867286682128906\n",
            "Epoch 8/12, Step 1400/2391, Loss: 43.004127502441406\n",
            "Epoch 8/12, Step 1500/2391, Loss: 36.207191467285156\n",
            "Epoch 8/12, Step 1600/2391, Loss: 30.609350204467773\n",
            "Epoch 8/12, Step 1700/2391, Loss: 57.059322357177734\n",
            "Epoch 8/12, Step 1800/2391, Loss: 28.60140609741211\n",
            "Epoch 8/12, Step 1900/2391, Loss: 44.49091339111328\n",
            "Epoch 8/12, Step 2000/2391, Loss: 26.549774169921875\n",
            "Epoch 8/12, Step 2100/2391, Loss: 32.95076370239258\n",
            "Epoch 8/12, Step 2200/2391, Loss: 27.788915634155273\n",
            "Epoch 8/12, Step 2300/2391, Loss: 31.364246368408203\n",
            "Epoch [8/12], Training Loss: 36.113938729267446, Validation Loss: 28.79046630859375\n",
            "Epoch 9/12, Step 0/2391, Loss: 26.809133529663086\n",
            "Epoch 9/12, Step 100/2391, Loss: 23.70287322998047\n",
            "Epoch 9/12, Step 200/2391, Loss: 26.74340057373047\n",
            "Epoch 9/12, Step 300/2391, Loss: 24.951169967651367\n",
            "Epoch 9/12, Step 400/2391, Loss: 29.669967651367188\n",
            "Epoch 9/12, Step 500/2391, Loss: 28.7265682220459\n",
            "Epoch 9/12, Step 600/2391, Loss: 27.535734176635742\n",
            "Epoch 9/12, Step 700/2391, Loss: 34.44330978393555\n",
            "Epoch 9/12, Step 800/2391, Loss: 27.451040267944336\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}