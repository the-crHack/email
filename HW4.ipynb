{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-crHack/email/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install unzip\n",
        "!pip install py_midicsv==4.1.2\n",
        "!pip install midi_player==0.5.1\n",
        "!unzip /content/sample_data/train-20241205T181153Z-001.zip -d /content/sample_data\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "dx2nwwkduYH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "95jdgV1JkGIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flEaVo0bc_nq",
        "outputId": "c06c0ddc-2ed0-4441-9177-19f6de19d6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-fe026d53549e>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  song_data = torch.load(file)  # song_data should be a tensor with shape (num_events, 4)\n",
            "<ipython-input-9-fe026d53549e>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Step 0/3137, Loss: 2.734126788509696e+16\n",
            "Epoch 1/10, Step 100/3137, Loss: 26808.259765625\n",
            "Epoch 1/10, Step 200/3137, Loss: 32950.75390625\n",
            "Epoch 1/10, Step 300/3137, Loss: 21294.27734375\n",
            "Epoch 1/10, Step 400/3137, Loss: 11856.4541015625\n",
            "Epoch 1/10, Step 500/3137, Loss: 12486.376953125\n",
            "Epoch 1/10, Step 600/3137, Loss: 3511.6005859375\n",
            "Epoch 1/10, Step 700/3137, Loss: 4153.23876953125\n",
            "Epoch 1/10, Step 800/3137, Loss: 1770.8980712890625\n",
            "Epoch 1/10, Step 900/3137, Loss: 2149.334716796875\n",
            "Epoch 1/10, Step 1000/3137, Loss: 2367.224609375\n",
            "Epoch 1/10, Step 1100/3137, Loss: 1040.6025390625\n",
            "Epoch 1/10, Step 1200/3137, Loss: 848.9593505859375\n",
            "Epoch 1/10, Step 1300/3137, Loss: 1823.048828125\n",
            "Epoch 1/10, Step 1400/3137, Loss: 838.4359130859375\n",
            "Epoch 1/10, Step 1500/3137, Loss: 1144.5040283203125\n",
            "Epoch 1/10, Step 1600/3137, Loss: 416.8633728027344\n",
            "Epoch 1/10, Step 1700/3137, Loss: 498.9329833984375\n",
            "Epoch 1/10, Step 1800/3137, Loss: 2997.6513671875\n",
            "Epoch 1/10, Step 1900/3137, Loss: 1015.3886108398438\n",
            "Epoch 1/10, Step 2000/3137, Loss: 695.1067504882812\n",
            "Epoch 1/10, Step 2100/3137, Loss: 889.6067504882812\n",
            "Epoch 1/10, Step 2200/3137, Loss: 558.4788208007812\n",
            "Epoch 1/10, Step 2300/3137, Loss: 400.74591064453125\n",
            "Epoch 1/10, Step 2400/3137, Loss: 411.16790771484375\n",
            "Epoch 1/10, Step 2500/3137, Loss: 899.8050537109375\n",
            "Epoch 1/10, Step 2600/3137, Loss: 261.3392028808594\n",
            "Epoch 1/10, Step 2700/3137, Loss: 474.6447448730469\n",
            "Epoch 1/10, Step 2800/3137, Loss: 521.3226928710938\n",
            "Epoch 1/10, Step 2900/3137, Loss: 686.234619140625\n",
            "Epoch 1/10, Step 3000/3137, Loss: 1423.48193359375\n",
            "Epoch 1/10, Step 3100/3137, Loss: 477.9063415527344\n",
            "Epoch [1/10], Loss: 16671039017406.766\n",
            "Epoch 2/10, Step 0/3137, Loss: 596.7495727539062\n",
            "Epoch 2/10, Step 100/3137, Loss: 355.0173645019531\n",
            "Epoch 2/10, Step 200/3137, Loss: 448.167724609375\n",
            "Epoch 2/10, Step 300/3137, Loss: 316.350341796875\n",
            "Epoch 2/10, Step 400/3137, Loss: 1169.813720703125\n",
            "Epoch 2/10, Step 500/3137, Loss: 418.0199890136719\n",
            "Epoch 2/10, Step 600/3137, Loss: 343.956298828125\n",
            "Epoch 2/10, Step 700/3137, Loss: 427.1899108886719\n",
            "Epoch 2/10, Step 800/3137, Loss: 357.08123779296875\n",
            "Epoch 2/10, Step 900/3137, Loss: 278.72003173828125\n",
            "Epoch 2/10, Step 1000/3137, Loss: 108.5278549194336\n",
            "Epoch 2/10, Step 1100/3137, Loss: 293.0443420410156\n",
            "Epoch 2/10, Step 1200/3137, Loss: 488.12945556640625\n",
            "Epoch 2/10, Step 1300/3137, Loss: 706.2177734375\n",
            "Epoch 2/10, Step 1400/3137, Loss: 336.81439208984375\n",
            "Epoch 2/10, Step 1500/3137, Loss: 286.39739990234375\n",
            "Epoch 2/10, Step 1600/3137, Loss: 406.6639404296875\n",
            "Epoch 2/10, Step 1700/3137, Loss: 259.59478759765625\n",
            "Epoch 2/10, Step 1800/3137, Loss: 843.7005615234375\n",
            "Epoch 2/10, Step 1900/3137, Loss: 182.03160095214844\n",
            "Epoch 2/10, Step 2000/3137, Loss: 234.19532775878906\n",
            "Epoch 2/10, Step 2100/3137, Loss: 202.4038543701172\n",
            "Epoch 2/10, Step 2200/3137, Loss: 353.82012939453125\n",
            "Epoch 2/10, Step 2300/3137, Loss: 158.61376953125\n",
            "Epoch 2/10, Step 2400/3137, Loss: 387.2558288574219\n",
            "Epoch 2/10, Step 2500/3137, Loss: 218.79180908203125\n",
            "Epoch 2/10, Step 2600/3137, Loss: 593.7001342773438\n",
            "Epoch 2/10, Step 2700/3137, Loss: 116.6937484741211\n",
            "Epoch 2/10, Step 2800/3137, Loss: 221.13780212402344\n",
            "Epoch 2/10, Step 2900/3137, Loss: 152.53469848632812\n",
            "Epoch 2/10, Step 3000/3137, Loss: 251.38107299804688\n",
            "Epoch 2/10, Step 3100/3137, Loss: 431.238037109375\n",
            "Epoch [2/10], Loss: 446.04832173944243\n",
            "Epoch 3/10, Step 0/3137, Loss: 245.37646484375\n",
            "Epoch 3/10, Step 100/3137, Loss: 363.4090270996094\n",
            "Epoch 3/10, Step 200/3137, Loss: 157.59881591796875\n",
            "Epoch 3/10, Step 300/3137, Loss: 147.55673217773438\n",
            "Epoch 3/10, Step 400/3137, Loss: 221.55877685546875\n",
            "Epoch 3/10, Step 500/3137, Loss: 268.6183166503906\n",
            "Epoch 3/10, Step 600/3137, Loss: 128.25381469726562\n",
            "Epoch 3/10, Step 700/3137, Loss: 416.6824645996094\n",
            "Epoch 3/10, Step 800/3137, Loss: 504.5393371582031\n",
            "Epoch 3/10, Step 900/3137, Loss: 150.07691955566406\n",
            "Epoch 3/10, Step 1000/3137, Loss: 208.8037109375\n",
            "Epoch 3/10, Step 1100/3137, Loss: 196.98049926757812\n",
            "Epoch 3/10, Step 1200/3137, Loss: 285.85772705078125\n",
            "Epoch 3/10, Step 1300/3137, Loss: 97.7330093383789\n",
            "Epoch 3/10, Step 1400/3137, Loss: 94.26879119873047\n",
            "Epoch 3/10, Step 1500/3137, Loss: 84.4743881225586\n",
            "Epoch 3/10, Step 1600/3137, Loss: 481.9966125488281\n",
            "Epoch 3/10, Step 1700/3137, Loss: 175.78692626953125\n",
            "Epoch 3/10, Step 1800/3137, Loss: 113.29354095458984\n",
            "Epoch 3/10, Step 1900/3137, Loss: 489.0357360839844\n",
            "Epoch 3/10, Step 2000/3137, Loss: 101.57901763916016\n",
            "Epoch 3/10, Step 2100/3137, Loss: 710.4210205078125\n",
            "Epoch 3/10, Step 2200/3137, Loss: 116.6244125366211\n",
            "Epoch 3/10, Step 2300/3137, Loss: 84.4244155883789\n",
            "Epoch 3/10, Step 2400/3137, Loss: 164.9806365966797\n",
            "Epoch 3/10, Step 2500/3137, Loss: 282.8123779296875\n",
            "Epoch 3/10, Step 2600/3137, Loss: 226.72369384765625\n",
            "Epoch 3/10, Step 2700/3137, Loss: 62.40037536621094\n",
            "Epoch 3/10, Step 2800/3137, Loss: 60.19446563720703\n",
            "Epoch 3/10, Step 2900/3137, Loss: 178.99197387695312\n",
            "Epoch 3/10, Step 3000/3137, Loss: 150.12576293945312\n",
            "Epoch 3/10, Step 3100/3137, Loss: 111.42609405517578\n",
            "Epoch [3/10], Loss: 202.78554384002345\n",
            "Epoch 4/10, Step 0/3137, Loss: 115.2586441040039\n",
            "Epoch 4/10, Step 100/3137, Loss: 83.75389099121094\n",
            "Epoch 4/10, Step 200/3137, Loss: 164.24195861816406\n",
            "Epoch 4/10, Step 300/3137, Loss: 111.1146469116211\n",
            "Epoch 4/10, Step 400/3137, Loss: 129.2399139404297\n",
            "Epoch 4/10, Step 500/3137, Loss: 103.5970230102539\n",
            "Epoch 4/10, Step 600/3137, Loss: 78.395751953125\n",
            "Epoch 4/10, Step 700/3137, Loss: 119.4968490600586\n",
            "Epoch 4/10, Step 800/3137, Loss: 224.20924377441406\n",
            "Epoch 4/10, Step 900/3137, Loss: 138.7493133544922\n",
            "Epoch 4/10, Step 1000/3137, Loss: 104.39409637451172\n",
            "Epoch 4/10, Step 1100/3137, Loss: 116.15022277832031\n",
            "Epoch 4/10, Step 1200/3137, Loss: 146.0580596923828\n",
            "Epoch 4/10, Step 1300/3137, Loss: 81.47850799560547\n",
            "Epoch 4/10, Step 1400/3137, Loss: 156.5172882080078\n",
            "Epoch 4/10, Step 1500/3137, Loss: 44.79974365234375\n",
            "Epoch 4/10, Step 1600/3137, Loss: 108.73030090332031\n",
            "Epoch 4/10, Step 1700/3137, Loss: 56.66259002685547\n",
            "Epoch 4/10, Step 1800/3137, Loss: 53.15559768676758\n",
            "Epoch 4/10, Step 1900/3137, Loss: 54.05976867675781\n",
            "Epoch 4/10, Step 2000/3137, Loss: 69.16327667236328\n",
            "Epoch 4/10, Step 2100/3137, Loss: 66.85635375976562\n",
            "Epoch 4/10, Step 2200/3137, Loss: 276.1091613769531\n",
            "Epoch 4/10, Step 2300/3137, Loss: 85.52640533447266\n",
            "Epoch 4/10, Step 2400/3137, Loss: 89.85728454589844\n",
            "Epoch 4/10, Step 2500/3137, Loss: 176.65469360351562\n",
            "Epoch 4/10, Step 2600/3137, Loss: 62.0328254699707\n",
            "Epoch 4/10, Step 2700/3137, Loss: 134.66189575195312\n",
            "Epoch 4/10, Step 2800/3137, Loss: 104.7372817993164\n",
            "Epoch 4/10, Step 2900/3137, Loss: 77.69965362548828\n",
            "Epoch 4/10, Step 3000/3137, Loss: 41.78046798706055\n",
            "Epoch 4/10, Step 3100/3137, Loss: 63.87667465209961\n",
            "Epoch [4/10], Loss: 106.30279742329981\n",
            "Epoch 5/10, Step 0/3137, Loss: 65.82929992675781\n",
            "Epoch 5/10, Step 100/3137, Loss: 36.76409912109375\n",
            "Epoch 5/10, Step 200/3137, Loss: 63.612403869628906\n",
            "Epoch 5/10, Step 300/3137, Loss: 182.16656494140625\n",
            "Epoch 5/10, Step 400/3137, Loss: 72.43859100341797\n",
            "Epoch 5/10, Step 500/3137, Loss: 43.01276397705078\n",
            "Epoch 5/10, Step 600/3137, Loss: 115.08222198486328\n",
            "Epoch 5/10, Step 700/3137, Loss: 57.49748611450195\n",
            "Epoch 5/10, Step 800/3137, Loss: 57.26591110229492\n",
            "Epoch 5/10, Step 900/3137, Loss: 68.89260864257812\n",
            "Epoch 5/10, Step 1000/3137, Loss: 49.748741149902344\n",
            "Epoch 5/10, Step 1100/3137, Loss: 66.10786437988281\n",
            "Epoch 5/10, Step 1200/3137, Loss: 110.29216766357422\n",
            "Epoch 5/10, Step 1300/3137, Loss: 59.29283142089844\n",
            "Epoch 5/10, Step 1400/3137, Loss: 52.629127502441406\n",
            "Epoch 5/10, Step 1500/3137, Loss: 51.0469856262207\n",
            "Epoch 5/10, Step 1600/3137, Loss: 49.154754638671875\n",
            "Epoch 5/10, Step 1700/3137, Loss: 63.99856948852539\n",
            "Epoch 5/10, Step 1800/3137, Loss: 54.95132064819336\n",
            "Epoch 5/10, Step 1900/3137, Loss: 50.21866989135742\n",
            "Epoch 5/10, Step 2000/3137, Loss: 54.07533645629883\n",
            "Epoch 5/10, Step 2100/3137, Loss: 64.22212219238281\n",
            "Epoch 5/10, Step 2200/3137, Loss: 51.82662582397461\n",
            "Epoch 5/10, Step 2300/3137, Loss: 38.50020217895508\n",
            "Epoch 5/10, Step 2400/3137, Loss: 68.6773910522461\n",
            "Epoch 5/10, Step 2500/3137, Loss: 40.630714416503906\n",
            "Epoch 5/10, Step 2600/3137, Loss: 34.56986999511719\n",
            "Epoch 5/10, Step 2700/3137, Loss: 77.41385650634766\n",
            "Epoch 5/10, Step 2800/3137, Loss: 61.15316390991211\n",
            "Epoch 5/10, Step 2900/3137, Loss: 34.91056442260742\n",
            "Epoch 5/10, Step 3000/3137, Loss: 36.404624938964844\n",
            "Epoch 5/10, Step 3100/3137, Loss: 39.74686050415039\n",
            "Epoch [5/10], Loss: 63.74829499266274\n",
            "Epoch 6/10, Step 0/3137, Loss: 54.98412322998047\n",
            "Epoch 6/10, Step 100/3137, Loss: 39.66289520263672\n",
            "Epoch 6/10, Step 200/3137, Loss: 30.3575382232666\n",
            "Epoch 6/10, Step 300/3137, Loss: 33.8502197265625\n",
            "Epoch 6/10, Step 400/3137, Loss: 88.07727813720703\n",
            "Epoch 6/10, Step 500/3137, Loss: 35.45278549194336\n",
            "Epoch 6/10, Step 600/3137, Loss: 98.24493408203125\n",
            "Epoch 6/10, Step 700/3137, Loss: 38.466461181640625\n",
            "Epoch 6/10, Step 800/3137, Loss: 83.88992309570312\n",
            "Epoch 6/10, Step 900/3137, Loss: 47.73762512207031\n",
            "Epoch 6/10, Step 1000/3137, Loss: 66.64348602294922\n",
            "Epoch 6/10, Step 1100/3137, Loss: 60.73125457763672\n",
            "Epoch 6/10, Step 1200/3137, Loss: 64.89691925048828\n",
            "Epoch 6/10, Step 1300/3137, Loss: 57.77943420410156\n",
            "Epoch 6/10, Step 1400/3137, Loss: 98.88208770751953\n",
            "Epoch 6/10, Step 1500/3137, Loss: 45.5098762512207\n",
            "Epoch 6/10, Step 1600/3137, Loss: 32.5179328918457\n",
            "Epoch 6/10, Step 1700/3137, Loss: 41.913970947265625\n",
            "Epoch 6/10, Step 1800/3137, Loss: 52.39425277709961\n",
            "Epoch 6/10, Step 1900/3137, Loss: 33.125308990478516\n",
            "Epoch 6/10, Step 2000/3137, Loss: 58.19697570800781\n",
            "Epoch 6/10, Step 2100/3137, Loss: 40.88313293457031\n",
            "Epoch 6/10, Step 2200/3137, Loss: 32.31637954711914\n",
            "Epoch 6/10, Step 2300/3137, Loss: 40.53466796875\n",
            "Epoch 6/10, Step 2400/3137, Loss: 29.892589569091797\n",
            "Epoch 6/10, Step 2500/3137, Loss: 27.956520080566406\n",
            "Epoch 6/10, Step 2600/3137, Loss: 40.48311233520508\n",
            "Epoch 6/10, Step 2700/3137, Loss: 42.229469299316406\n",
            "Epoch 6/10, Step 2800/3137, Loss: 33.55888366699219\n",
            "Epoch 6/10, Step 2900/3137, Loss: 48.70782470703125\n",
            "Epoch 6/10, Step 3000/3137, Loss: 32.668270111083984\n",
            "Epoch 6/10, Step 3100/3137, Loss: 31.40557289123535\n",
            "Epoch [6/10], Loss: 43.63795955172762\n",
            "Epoch 7/10, Step 0/3137, Loss: 25.857826232910156\n",
            "Epoch 7/10, Step 100/3137, Loss: 35.433204650878906\n",
            "Epoch 7/10, Step 200/3137, Loss: 25.283342361450195\n",
            "Epoch 7/10, Step 300/3137, Loss: 38.81588363647461\n",
            "Epoch 7/10, Step 400/3137, Loss: 39.1751594543457\n",
            "Epoch 7/10, Step 500/3137, Loss: 28.523725509643555\n",
            "Epoch 7/10, Step 600/3137, Loss: 38.422637939453125\n",
            "Epoch 7/10, Step 700/3137, Loss: 30.68117904663086\n",
            "Epoch 7/10, Step 800/3137, Loss: 40.94983673095703\n",
            "Epoch 7/10, Step 900/3137, Loss: 34.65913391113281\n",
            "Epoch 7/10, Step 1000/3137, Loss: 32.31116485595703\n",
            "Epoch 7/10, Step 1100/3137, Loss: 50.85531997680664\n",
            "Epoch 7/10, Step 1200/3137, Loss: 28.085651397705078\n",
            "Epoch 7/10, Step 1300/3137, Loss: 34.45648193359375\n",
            "Epoch 7/10, Step 1400/3137, Loss: 32.07331085205078\n",
            "Epoch 7/10, Step 1500/3137, Loss: 28.951812744140625\n",
            "Epoch 7/10, Step 1600/3137, Loss: 37.00563049316406\n",
            "Epoch 7/10, Step 1700/3137, Loss: 28.924259185791016\n",
            "Epoch 7/10, Step 1800/3137, Loss: 36.42839813232422\n",
            "Epoch 7/10, Step 1900/3137, Loss: 29.357711791992188\n",
            "Epoch 7/10, Step 2000/3137, Loss: 32.2985954284668\n",
            "Epoch 7/10, Step 2100/3137, Loss: 23.91097068786621\n",
            "Epoch 7/10, Step 2200/3137, Loss: 28.272109985351562\n",
            "Epoch 7/10, Step 2300/3137, Loss: 30.253971099853516\n",
            "Epoch 7/10, Step 2400/3137, Loss: 26.213529586791992\n",
            "Epoch 7/10, Step 2500/3137, Loss: 42.54124069213867\n",
            "Epoch 7/10, Step 2600/3137, Loss: 28.397510528564453\n",
            "Epoch 7/10, Step 2700/3137, Loss: 30.52712059020996\n",
            "Epoch 7/10, Step 2800/3137, Loss: 27.928028106689453\n",
            "Epoch 7/10, Step 2900/3137, Loss: 30.131792068481445\n",
            "Epoch 7/10, Step 3000/3137, Loss: 26.688722610473633\n",
            "Epoch 7/10, Step 3100/3137, Loss: 38.17443084716797\n",
            "Epoch [7/10], Loss: 33.86307452915959\n",
            "Epoch 8/10, Step 0/3137, Loss: 42.77803039550781\n",
            "Epoch 8/10, Step 100/3137, Loss: 31.96596908569336\n",
            "Epoch 8/10, Step 200/3137, Loss: 27.09303855895996\n",
            "Epoch 8/10, Step 300/3137, Loss: 29.197433471679688\n",
            "Epoch 8/10, Step 400/3137, Loss: 30.214324951171875\n",
            "Epoch 8/10, Step 500/3137, Loss: 27.476564407348633\n",
            "Epoch 8/10, Step 600/3137, Loss: 27.905773162841797\n",
            "Epoch 8/10, Step 700/3137, Loss: 27.346521377563477\n",
            "Epoch 8/10, Step 800/3137, Loss: 30.154891967773438\n",
            "Epoch 8/10, Step 900/3137, Loss: 26.093263626098633\n",
            "Epoch 8/10, Step 1000/3137, Loss: 29.89035987854004\n",
            "Epoch 8/10, Step 1100/3137, Loss: 28.162750244140625\n",
            "Epoch 8/10, Step 1200/3137, Loss: 25.932178497314453\n",
            "Epoch 8/10, Step 1300/3137, Loss: 28.531047821044922\n",
            "Epoch 8/10, Step 1400/3137, Loss: 30.97658348083496\n",
            "Epoch 8/10, Step 1500/3137, Loss: 26.426639556884766\n",
            "Epoch 8/10, Step 1600/3137, Loss: 28.160839080810547\n",
            "Epoch 8/10, Step 1700/3137, Loss: 35.799774169921875\n",
            "Epoch 8/10, Step 1800/3137, Loss: 27.090808868408203\n",
            "Epoch 8/10, Step 1900/3137, Loss: 25.62525749206543\n",
            "Epoch 8/10, Step 2000/3137, Loss: 27.13918113708496\n",
            "Epoch 8/10, Step 2100/3137, Loss: 28.92280387878418\n",
            "Epoch 8/10, Step 2200/3137, Loss: 30.83125877380371\n",
            "Epoch 8/10, Step 2300/3137, Loss: 27.762950897216797\n",
            "Epoch 8/10, Step 2400/3137, Loss: 29.98733139038086\n",
            "Epoch 8/10, Step 2500/3137, Loss: 25.0487060546875\n",
            "Epoch 8/10, Step 2600/3137, Loss: 29.039520263671875\n",
            "Epoch 8/10, Step 2700/3137, Loss: 26.018497467041016\n",
            "Epoch 8/10, Step 2800/3137, Loss: 29.39670753479004\n",
            "Epoch 8/10, Step 2900/3137, Loss: 33.827938079833984\n",
            "Epoch 8/10, Step 3000/3137, Loss: 28.31720542907715\n",
            "Epoch 8/10, Step 3100/3137, Loss: 26.357433319091797\n",
            "Epoch [8/10], Loss: 28.970403544797158\n",
            "Epoch 9/10, Step 0/3137, Loss: 25.972858428955078\n",
            "Epoch 9/10, Step 100/3137, Loss: 25.153423309326172\n",
            "Epoch 9/10, Step 200/3137, Loss: 24.65880584716797\n",
            "Epoch 9/10, Step 300/3137, Loss: 36.84596633911133\n",
            "Epoch 9/10, Step 400/3137, Loss: 26.66274070739746\n",
            "Epoch 9/10, Step 500/3137, Loss: 24.838455200195312\n",
            "Epoch 9/10, Step 600/3137, Loss: 31.940534591674805\n",
            "Epoch 9/10, Step 700/3137, Loss: 34.805294036865234\n",
            "Epoch 9/10, Step 800/3137, Loss: 27.559093475341797\n",
            "Epoch 9/10, Step 900/3137, Loss: 25.748550415039062\n",
            "Epoch 9/10, Step 1000/3137, Loss: 25.474720001220703\n",
            "Epoch 9/10, Step 1100/3137, Loss: 25.36701774597168\n",
            "Epoch 9/10, Step 1200/3137, Loss: 27.74606704711914\n",
            "Epoch 9/10, Step 1300/3137, Loss: 28.244579315185547\n",
            "Epoch 9/10, Step 1400/3137, Loss: 24.86587142944336\n",
            "Epoch 9/10, Step 1500/3137, Loss: 29.75130844116211\n",
            "Epoch 9/10, Step 1600/3137, Loss: 23.514787673950195\n",
            "Epoch 9/10, Step 1700/3137, Loss: 23.37875747680664\n",
            "Epoch 9/10, Step 1800/3137, Loss: 26.48046875\n",
            "Epoch 9/10, Step 1900/3137, Loss: 28.306344985961914\n",
            "Epoch 9/10, Step 2000/3137, Loss: 25.624317169189453\n",
            "Epoch 9/10, Step 2100/3137, Loss: 28.765798568725586\n",
            "Epoch 9/10, Step 2200/3137, Loss: 25.627119064331055\n",
            "Epoch 9/10, Step 2300/3137, Loss: 23.701126098632812\n",
            "Epoch 9/10, Step 2400/3137, Loss: 22.243282318115234\n",
            "Epoch 9/10, Step 2500/3137, Loss: 23.251619338989258\n",
            "Epoch 9/10, Step 2600/3137, Loss: 24.90251922607422\n",
            "Epoch 9/10, Step 2700/3137, Loss: 21.81390953063965\n",
            "Epoch 9/10, Step 2800/3137, Loss: 22.79724884033203\n",
            "Epoch 9/10, Step 2900/3137, Loss: 23.40734100341797\n",
            "Epoch 9/10, Step 3000/3137, Loss: 23.121591567993164\n",
            "Epoch 9/10, Step 3100/3137, Loss: 27.13793182373047\n",
            "Epoch [9/10], Loss: 25.891951256661724\n",
            "Epoch 10/10, Step 0/3137, Loss: 25.115158081054688\n",
            "Epoch 10/10, Step 100/3137, Loss: 23.214811325073242\n",
            "Epoch 10/10, Step 200/3137, Loss: 24.752525329589844\n",
            "Epoch 10/10, Step 300/3137, Loss: 24.012855529785156\n",
            "Epoch 10/10, Step 400/3137, Loss: 25.46181297302246\n",
            "Epoch 10/10, Step 500/3137, Loss: 23.396385192871094\n",
            "Epoch 10/10, Step 600/3137, Loss: 23.213397979736328\n",
            "Epoch 10/10, Step 700/3137, Loss: 22.89435577392578\n",
            "Epoch 10/10, Step 800/3137, Loss: 23.743968963623047\n",
            "Epoch 10/10, Step 900/3137, Loss: 23.328014373779297\n",
            "Epoch 10/10, Step 1000/3137, Loss: 22.68661117553711\n",
            "Epoch 10/10, Step 1100/3137, Loss: 23.335479736328125\n",
            "Epoch 10/10, Step 1200/3137, Loss: 24.797985076904297\n",
            "Epoch 10/10, Step 1300/3137, Loss: 22.228534698486328\n",
            "Epoch 10/10, Step 1400/3137, Loss: 22.442033767700195\n",
            "Epoch 10/10, Step 1500/3137, Loss: 24.213768005371094\n",
            "Epoch 10/10, Step 1600/3137, Loss: 22.773950576782227\n",
            "Epoch 10/10, Step 1700/3137, Loss: 25.178781509399414\n",
            "Epoch 10/10, Step 1800/3137, Loss: 23.45110511779785\n",
            "Epoch 10/10, Step 1900/3137, Loss: 24.956928253173828\n",
            "Epoch 10/10, Step 2000/3137, Loss: 23.571495056152344\n",
            "Epoch 10/10, Step 2100/3137, Loss: 22.658226013183594\n",
            "Epoch 10/10, Step 2200/3137, Loss: 22.64487075805664\n",
            "Epoch 10/10, Step 2300/3137, Loss: 27.067996978759766\n",
            "Epoch 10/10, Step 2400/3137, Loss: 22.883159637451172\n",
            "Epoch 10/10, Step 2500/3137, Loss: 23.111013412475586\n",
            "Epoch 10/10, Step 2600/3137, Loss: 22.01154327392578\n",
            "Epoch 10/10, Step 2700/3137, Loss: 29.65399169921875\n",
            "Epoch 10/10, Step 2800/3137, Loss: 22.282238006591797\n",
            "Epoch 10/10, Step 2900/3137, Loss: 22.020166397094727\n",
            "Epoch 10/10, Step 3000/3137, Loss: 22.485219955444336\n",
            "Epoch 10/10, Step 3100/3137, Loss: 22.366775512695312\n",
            "Epoch [10/10], Loss: 23.678807525221313\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class SongsDataset():\n",
        "    def __init__(self, files, context_window=64, stride=4, max_samples_per_song=100):\n",
        "        self.data = []  # List to store input sequences (X)\n",
        "        self.labels = []  # List to store corresponding labels (Y)\n",
        "\n",
        "        # Iterate over each song file\n",
        "        for file in files:\n",
        "            # Load the song data (assuming it's stored as a tensor)\n",
        "            song_data = torch.load(file)  # song_data should be a tensor with shape (num_events, 4)\n",
        "\n",
        "            # Create indices for sliding window\n",
        "            indices = range(0, len(song_data) - context_window, stride)\n",
        "            sampled_indices = random.sample(list(indices), min(max_samples_per_song, len(indices)))\n",
        "\n",
        "            # Extract data slices and labels\n",
        "            for i in sampled_indices:\n",
        "                # Input sequence: slice of notes with size `context_window`\n",
        "                self.data.append(song_data[i:i + context_window])  # Shape: (context_window, 4)\n",
        "                # Label: the next note after the context window\n",
        "                self.labels.append(song_data[i + context_window])  # Shape: (1, 4)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of samples in the dataset\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the input (X) and label (Y) for the given index\n",
        "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "\n",
        "# --- Model Definition ---\n",
        "\n",
        "class NotePredictionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NotePredictionModel, self).__init__()\n",
        "\n",
        "        # Define layers: A simple 2-layer LSTM followed by a fully connected layer\n",
        "        self.lstm = nn.LSTM(input_size=4, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 134)  # We predict 134 values: [µ_t, σ_t, µ_d, σ_d, log(π0), ..., log(π127), µ_v, σ_v]\n",
        "\n",
        "    def forward(self, x):\n",
        "      # LSTM layer\n",
        "      lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "      # Take the last LSTM output\n",
        "      last_output = lstm_out[:, -1, :]  # (batch_size, hidden_size)\n",
        "\n",
        "      # Fully connected layer to predict the required values\n",
        "      output = self.fc(last_output)  # Shape: (batch_size, 134)\n",
        "\n",
        "      # Split the output into the predicted values\n",
        "      # Expecting 134 values for [µ_t, σ_t, µ_d, σ_d, log(π0), ..., log(π127), µ_v, σ_v]\n",
        "      µ_t, σ_t, µ_d, σ_d, logits_n, µ_v, σ_v = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "\n",
        "\n",
        "      # Return the predicted values as a tensor of shape (batch_size, 134)\n",
        "      return torch.cat((µ_t, σ_t, µ_d, σ_d, logits_n, µ_v, σ_v), dim=-1)\n",
        "\n",
        "\n",
        "def nll_loss_continuous(pred_mu, pred_sigma, target):\n",
        "    # Avoid division by zero and log(0) errors\n",
        "    epsilon = 1e-6\n",
        "    pred_sigma = torch.max(pred_sigma, torch.tensor(epsilon))  # Prevent log(0)\n",
        "\n",
        "    # Calculate the NLL for normal distribution\n",
        "    loss = 0.5 * torch.log(2 * torch.tensor(torch.pi)) + torch.log(pred_sigma) + (target - pred_mu) ** 2 / (2 * pred_sigma ** 2)\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "def train_model(model, data_loader, epochs, learning_rate):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for step, (context, target) in enumerate(data_loader):\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(context)\n",
        "\n",
        "            # Split the output into predicted values (this should be 134 values)\n",
        "            µ_t_pred, σ_t_pred, µ_d_pred, σ_d_pred, logits_n_pred, µ_v_pred, σ_v_pred = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "            logits_n_pred = F.softmax(logits_n_pred, dim=-1)\n",
        "\n",
        "            # Calculate the loss for continuous distributions using NLL\n",
        "            t_loss = nll_loss_continuous(µ_t_pred, σ_t_pred, target[:, 0])\n",
        "            d_loss = nll_loss_continuous(µ_d_pred, σ_d_pred, target[:, 1])\n",
        "            v_loss = nll_loss_continuous(µ_v_pred, σ_v_pred, target[:, 2])\n",
        "\n",
        "            # Calculate the categorical cross entropy for the note value logits\n",
        "            nll_loss = nn.CrossEntropyLoss()(logits_n_pred, target[:, 3].long())\n",
        "\n",
        "            # Total loss\n",
        "            loss = t_loss + d_loss + v_loss + nll_loss\n",
        "\n",
        "            # Print loss every 100 steps\n",
        "            if step % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Step {step}/{len(data_loader)}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize the model\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader)}\")\n",
        "\n",
        "\n",
        "# Example of file list with paths (you need to replace these with actual paths)\n",
        "train_files = glob.glob(\"/content/sample_data/train/*/*/*/*.pt\")  # Replace with your actual data files\n",
        "\n",
        "# Initialize the dataset and dataloader\n",
        "context_window = 64  # Size of the context window\n",
        "stride = 4  # Step size\n",
        "max_samples_per_song = 300  # Max samples per song\n",
        "\n",
        "dataset = SongsDataset(train_files, context_window=context_window, stride=stride, max_samples_per_song=max_samples_per_song)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# --- Model Training ---\n",
        "\n",
        "# Initialize the model\n",
        "model = NotePredictionModel()\n",
        "\n",
        "# Train the model\n",
        "train_model(model, data_loader, epochs=10, learning_rate=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install unzip\n",
        "!unzip /content/sample_data/train-20241205T181153Z-001.zip -d /content/sample_data"
      ],
      "metadata": {
        "id": "l8DD2xU0kO2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import random\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Dataset Definition ---\n",
        "\n",
        "class SongsDataset(Dataset):\n",
        "    def __init__(self, files, context_window=64, stride=4, max_samples_per_song=250):\n",
        "        self.data = []  # List to store input sequences (X)\n",
        "        self.labels = []  # List to store corresponding labels (Y)\n",
        "\n",
        "        # Iterate over each song file\n",
        "        for file in files:\n",
        "            # Load the song data (assuming it's stored as a tensor)\n",
        "            song_data = torch.load(file)  # song_data should be a tensor with shape (num_events, 4)\n",
        "\n",
        "            # Create indices for sliding window with dynamic stride and sampling\n",
        "            indices = range(0, len(song_data) - context_window, stride)\n",
        "\n",
        "            # Sample a few indices for training (to avoid memory overload)\n",
        "            sampled_indices = random.sample(list(indices), min(max_samples_per_song, len(indices)))\n",
        "\n",
        "            # Extract data slices and labels\n",
        "            for i in sampled_indices:\n",
        "                # Input sequence: slice of notes with size `context_window`\n",
        "                self.data.append(song_data[i:i + context_window])  # Shape: (context_window, 4)\n",
        "                # Label: the next note after the context window\n",
        "                self.labels.append(song_data[i + context_window])  # Shape: (1, 4)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "class NotePredictionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NotePredictionModel, self).__init__()\n",
        "\n",
        "        # Define layers: A simple 2-layer LSTM followed by a fully connected layer\n",
        "        self.lstm = nn.LSTM(input_size=4, hidden_size=128, batch_first=True)\n",
        "        self.fc = nn.Linear(128, 134)  # We predict 134 values: [µ_t, σ_t, µ_d, σ_d, log(π0), ..., log(π127), µ_v, σ_v]\n",
        "\n",
        "    def forward(self, x):\n",
        "      # LSTM layer\n",
        "      lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "      # Take the last LSTM output\n",
        "      last_output = lstm_out[:, -1, :]  # (batch_size, hidden_size)\n",
        "\n",
        "      # Fully connected layer to predict the required values\n",
        "      output = self.fc(last_output)  # Shape: (batch_size, 134)\n",
        "\n",
        "      # Split the output into the predicted values\n",
        "      # Expecting 134 values for [µ_t, σ_t, µ_d, σ_d, log(π0), ..., log(π127), µ_v, σ_v]\n",
        "      µ_t, σ_t, µ_d, σ_d, logits_n, µ_v, σ_v = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "\n",
        "\n",
        "      # Return the predicted values as a tensor of shape (batch_size, 134)\n",
        "      return torch.cat((µ_t, σ_t, µ_d, σ_d, logits_n, µ_v, σ_v), dim=-1)\n",
        "\n",
        "\n",
        "# --- Loss Function ---\n",
        "\n",
        "def nll_loss_continuous(pred_mu, pred_sigma, target):\n",
        "    epsilon = 1e-6\n",
        "    pred_sigma = torch.max(pred_sigma, torch.tensor(epsilon))  # Prevent log(0)\n",
        "\n",
        "    loss = 0.5 * torch.log(2 * torch.tensor(torch.pi)) + torch.log(pred_sigma) + (target - pred_mu) ** 2 / (2 * pred_sigma ** 2)\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "# --- Training Function ---\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs, learning_rate, scheduler=None):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(12):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for step, (context, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(context)\n",
        "\n",
        "            # Split the output into predicted values\n",
        "            µ_t_pred, σ_t_pred, µ_d_pred, σ_d_pred, logits_n_pred, µ_v_pred, σ_v_pred = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "            logits_n_pred = F.softmax(logits_n_pred, dim=-1)\n",
        "\n",
        "            # Calculate the loss for continuous distributions using NLL\n",
        "            t_loss = nll_loss_continuous(µ_t_pred, σ_t_pred, target[:, 0])\n",
        "            d_loss = nll_loss_continuous(µ_d_pred, σ_d_pred, target[:, 1])\n",
        "            v_loss = nll_loss_continuous(µ_v_pred, σ_v_pred, target[:, 2])\n",
        "\n",
        "            # Calculate the categorical cross entropy for the note value logits\n",
        "            nll_loss = nn.CrossEntropyLoss()(logits_n_pred, target[:, 3].long())\n",
        "\n",
        "            # Total loss\n",
        "            loss = t_loss + d_loss + v_loss + nll_loss\n",
        "\n",
        "            if step % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Step {step}/{len(train_loader)}, Loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Optimize the model\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Log training loss\n",
        "        training_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "        # Validate after every epoch\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for context, target in val_loader:\n",
        "                output = model(context)\n",
        "                µ_t_pred, σ_t_pred, µ_d_pred, σ_d_pred, logits_n_pred, µ_v_pred, σ_v_pred = output.split([1, 1, 1, 1, 128, 1, 1], dim=-1)\n",
        "                logits_n_pred = F.softmax(logits_n_pred, dim=-1)\n",
        "\n",
        "                # Calculate the loss for validation\n",
        "                t_loss = nll_loss_continuous(µ_t_pred, σ_t_pred, target[:, 0])\n",
        "                d_loss = nll_loss_continuous(µ_d_pred, σ_d_pred, target[:, 1])\n",
        "                v_loss = nll_loss_continuous(µ_v_pred, σ_v_pred, target[:, 2])\n",
        "\n",
        "                nll_loss = nn.CrossEntropyLoss()(logits_n_pred, target[:, 3].long())\n",
        "                val_loss += t_loss + d_loss + v_loss + nll_loss\n",
        "\n",
        "        validation_losses.append(val_loss / len(val_loader))\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "    return training_losses, validation_losses\n",
        "\n",
        "\n",
        "# --- Dataset Preparation ---\n",
        "\n",
        "# Example of file list with paths (you need to replace these with actual paths)\n",
        "train_files = glob.glob(\"/content/sample_data/train/*/*/*/*.pt\")  # Replace with your actual data files\n",
        "\n",
        "# Initialize the dataset\n",
        "context_window = 64  # Size of the context window\n",
        "max_samples_per_song = 250  # Max samples per song\n",
        "stride = 4\n",
        "\n",
        "dataset = SongsDataset(train_files, context_window=context_window, stride = stride, max_samples_per_song=max_samples_per_song)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "val_size = len(dataset) - train_size  # 20% for validation\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader for training and validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# --- Model Initialization and Training ---\n",
        "\n",
        "# Initialize the model\n",
        "model = NotePredictionModel()  # Adding dropout for regularization\n",
        "\n",
        "# Train the model\n",
        "training_losses, validation_losses = train_model(model, train_loader, val_loader, epochs=12, learning_rate=0.01)\n",
        "\n",
        "# --- Plotting the Training and Validation Loss ---\n",
        "\n",
        "plt.plot(training_losses, label='Training Loss')\n",
        "plt.plot(validation_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kJiK_HeCXpP",
        "outputId": "6527232f-eaa5-46a8-8d0e-33bb49957f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9daac4b7be5b>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  song_data = torch.load(file)  # song_data should be a tensor with shape (num_events, 4)\n",
            "<ipython-input-5-9daac4b7be5b>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12, Step 0/2391, Loss: 4.860358938329088e+16\n",
            "Epoch 1/12, Step 100/2391, Loss: 2385.017333984375\n",
            "Epoch 1/12, Step 200/2391, Loss: 2411.20654296875\n",
            "Epoch 1/12, Step 300/2391, Loss: 1727.6552734375\n",
            "Epoch 1/12, Step 400/2391, Loss: 1961.35498046875\n",
            "Epoch 1/12, Step 500/2391, Loss: 2580.5673828125\n",
            "Epoch 1/12, Step 600/2391, Loss: 1045.5284423828125\n",
            "Epoch 1/12, Step 700/2391, Loss: 1213.0501708984375\n",
            "Epoch 1/12, Step 800/2391, Loss: 1309.9677734375\n",
            "Epoch 1/12, Step 900/2391, Loss: 1297.3577880859375\n",
            "Epoch 1/12, Step 1000/2391, Loss: 1541.7164306640625\n",
            "Epoch 1/12, Step 1100/2391, Loss: 709.4432373046875\n",
            "Epoch 1/12, Step 1200/2391, Loss: 1057.7952880859375\n",
            "Epoch 1/12, Step 1300/2391, Loss: 837.0156860351562\n",
            "Epoch 1/12, Step 1400/2391, Loss: 883.5498046875\n",
            "Epoch 1/12, Step 1500/2391, Loss: 1008.971435546875\n",
            "Epoch 1/12, Step 1600/2391, Loss: 757.1150512695312\n",
            "Epoch 1/12, Step 1700/2391, Loss: 423.9794921875\n",
            "Epoch 1/12, Step 1800/2391, Loss: 465.5028381347656\n",
            "Epoch 1/12, Step 1900/2391, Loss: 673.330810546875\n",
            "Epoch 1/12, Step 2000/2391, Loss: 646.8651733398438\n",
            "Epoch 1/12, Step 2100/2391, Loss: 372.5273132324219\n",
            "Epoch 1/12, Step 2200/2391, Loss: 381.489013671875\n",
            "Epoch 1/12, Step 2300/2391, Loss: 370.89459228515625\n",
            "Epoch [1/12], Training Loss: 23395072507585.69, Validation Loss: 512.4645385742188\n",
            "Epoch 2/12, Step 0/2391, Loss: 582.3849487304688\n",
            "Epoch 2/12, Step 100/2391, Loss: 214.76234436035156\n",
            "Epoch 2/12, Step 200/2391, Loss: 483.66290283203125\n",
            "Epoch 2/12, Step 300/2391, Loss: 555.7144775390625\n",
            "Epoch 2/12, Step 400/2391, Loss: 265.5112609863281\n",
            "Epoch 2/12, Step 500/2391, Loss: 438.7557678222656\n",
            "Epoch 2/12, Step 600/2391, Loss: 385.9020080566406\n",
            "Epoch 2/12, Step 700/2391, Loss: 287.8509216308594\n",
            "Epoch 2/12, Step 800/2391, Loss: 247.7819061279297\n",
            "Epoch 2/12, Step 900/2391, Loss: 311.6301574707031\n",
            "Epoch 2/12, Step 1000/2391, Loss: 422.52838134765625\n",
            "Epoch 2/12, Step 1100/2391, Loss: 296.94805908203125\n",
            "Epoch 2/12, Step 1200/2391, Loss: 214.18533325195312\n",
            "Epoch 2/12, Step 1300/2391, Loss: 269.5551452636719\n",
            "Epoch 2/12, Step 1400/2391, Loss: 209.70382690429688\n",
            "Epoch 2/12, Step 1500/2391, Loss: 91.559814453125\n",
            "Epoch 2/12, Step 1600/2391, Loss: 237.64561462402344\n",
            "Epoch 2/12, Step 1700/2391, Loss: 502.9476013183594\n",
            "Epoch 2/12, Step 1800/2391, Loss: 281.51904296875\n",
            "Epoch 2/12, Step 1900/2391, Loss: 662.3195190429688\n",
            "Epoch 2/12, Step 2000/2391, Loss: 176.0198974609375\n",
            "Epoch 2/12, Step 2100/2391, Loss: 490.2978515625\n",
            "Epoch 2/12, Step 2200/2391, Loss: 158.81326293945312\n",
            "Epoch 2/12, Step 2300/2391, Loss: 310.8328857421875\n",
            "Epoch [2/12], Training Loss: 345.7518490528472, Validation Loss: 230.32188415527344\n",
            "Epoch 3/12, Step 0/2391, Loss: 111.53235626220703\n",
            "Epoch 3/12, Step 100/2391, Loss: 214.56637573242188\n",
            "Epoch 3/12, Step 200/2391, Loss: 155.49801635742188\n",
            "Epoch 3/12, Step 300/2391, Loss: 195.0280303955078\n",
            "Epoch 3/12, Step 400/2391, Loss: 144.25437927246094\n",
            "Epoch 3/12, Step 500/2391, Loss: 189.50442504882812\n",
            "Epoch 3/12, Step 600/2391, Loss: 171.4939422607422\n",
            "Epoch 3/12, Step 700/2391, Loss: 116.4926528930664\n",
            "Epoch 3/12, Step 800/2391, Loss: 196.37107849121094\n",
            "Epoch 3/12, Step 900/2391, Loss: 697.0821533203125\n",
            "Epoch 3/12, Step 1000/2391, Loss: 143.5477294921875\n",
            "Epoch 3/12, Step 1100/2391, Loss: 112.6507797241211\n",
            "Epoch 3/12, Step 1200/2391, Loss: 127.47039031982422\n",
            "Epoch 3/12, Step 1300/2391, Loss: 181.8492431640625\n",
            "Epoch 3/12, Step 1400/2391, Loss: 76.54904174804688\n",
            "Epoch 3/12, Step 1500/2391, Loss: 147.18434143066406\n",
            "Epoch 3/12, Step 1600/2391, Loss: 51.405555725097656\n",
            "Epoch 3/12, Step 1700/2391, Loss: 113.98210144042969\n",
            "Epoch 3/12, Step 1800/2391, Loss: 110.416259765625\n",
            "Epoch 3/12, Step 1900/2391, Loss: 156.06170654296875\n",
            "Epoch 3/12, Step 2000/2391, Loss: 65.04733276367188\n",
            "Epoch 3/12, Step 2100/2391, Loss: 78.0879135131836\n",
            "Epoch 3/12, Step 2200/2391, Loss: 132.38140869140625\n",
            "Epoch 3/12, Step 2300/2391, Loss: 44.67240905761719\n",
            "Epoch [3/12], Training Loss: 171.05678469962228, Validation Loss: 123.91382598876953\n",
            "Epoch 4/12, Step 0/2391, Loss: 86.53297424316406\n",
            "Epoch 4/12, Step 100/2391, Loss: 164.0932159423828\n",
            "Epoch 4/12, Step 200/2391, Loss: 89.66295623779297\n",
            "Epoch 4/12, Step 300/2391, Loss: 69.37576293945312\n",
            "Epoch 4/12, Step 400/2391, Loss: 88.62248992919922\n",
            "Epoch 4/12, Step 500/2391, Loss: 93.75981903076172\n",
            "Epoch 4/12, Step 600/2391, Loss: 53.40959548950195\n",
            "Epoch 4/12, Step 700/2391, Loss: 59.43650817871094\n",
            "Epoch 4/12, Step 800/2391, Loss: 73.3365249633789\n",
            "Epoch 4/12, Step 900/2391, Loss: 92.32574462890625\n",
            "Epoch 4/12, Step 1000/2391, Loss: 134.04833984375\n",
            "Epoch 4/12, Step 1100/2391, Loss: 87.26740264892578\n",
            "Epoch 4/12, Step 1200/2391, Loss: 86.0499267578125\n",
            "Epoch 4/12, Step 1300/2391, Loss: 49.862403869628906\n",
            "Epoch 4/12, Step 1400/2391, Loss: 164.71466064453125\n",
            "Epoch 4/12, Step 1500/2391, Loss: 74.80927276611328\n",
            "Epoch 4/12, Step 1600/2391, Loss: 95.44217681884766\n",
            "Epoch 4/12, Step 1700/2391, Loss: 116.13695526123047\n",
            "Epoch 4/12, Step 1800/2391, Loss: 52.74559020996094\n",
            "Epoch 4/12, Step 1900/2391, Loss: 60.465728759765625\n",
            "Epoch 4/12, Step 2000/2391, Loss: 47.2850227355957\n",
            "Epoch 4/12, Step 2100/2391, Loss: 72.52269744873047\n",
            "Epoch 4/12, Step 2200/2391, Loss: 52.78573226928711\n",
            "Epoch 4/12, Step 2300/2391, Loss: 136.41929626464844\n",
            "Epoch [4/12], Training Loss: 96.37383512451478, Validation Loss: 73.72281646728516\n",
            "Epoch 5/12, Step 0/2391, Loss: 129.6493377685547\n",
            "Epoch 5/12, Step 100/2391, Loss: 90.98639678955078\n",
            "Epoch 5/12, Step 200/2391, Loss: 68.20462036132812\n",
            "Epoch 5/12, Step 300/2391, Loss: 83.57962799072266\n",
            "Epoch 5/12, Step 400/2391, Loss: 50.90850067138672\n",
            "Epoch 5/12, Step 500/2391, Loss: 126.68457794189453\n",
            "Epoch 5/12, Step 600/2391, Loss: 50.48443603515625\n",
            "Epoch 5/12, Step 700/2391, Loss: 45.66263198852539\n",
            "Epoch 5/12, Step 800/2391, Loss: 41.40848159790039\n",
            "Epoch 5/12, Step 900/2391, Loss: 85.95356750488281\n",
            "Epoch 5/12, Step 1000/2391, Loss: 64.22748565673828\n",
            "Epoch 5/12, Step 1100/2391, Loss: 73.4336166381836\n",
            "Epoch 5/12, Step 1200/2391, Loss: 74.99807739257812\n",
            "Epoch 5/12, Step 1300/2391, Loss: 48.171600341796875\n",
            "Epoch 5/12, Step 1400/2391, Loss: 33.88770294189453\n",
            "Epoch 5/12, Step 1500/2391, Loss: 41.44273376464844\n",
            "Epoch 5/12, Step 1600/2391, Loss: 45.541507720947266\n",
            "Epoch 5/12, Step 1700/2391, Loss: 27.65619468688965\n",
            "Epoch 5/12, Step 1800/2391, Loss: 34.361446380615234\n",
            "Epoch 5/12, Step 1900/2391, Loss: 69.61544799804688\n",
            "Epoch 5/12, Step 2000/2391, Loss: 65.60453796386719\n",
            "Epoch 5/12, Step 2100/2391, Loss: 42.7506103515625\n",
            "Epoch 5/12, Step 2200/2391, Loss: 47.863677978515625\n",
            "Epoch 5/12, Step 2300/2391, Loss: 45.277400970458984\n",
            "Epoch [5/12], Training Loss: 60.08232800584615, Validation Loss: 48.89146041870117\n",
            "Epoch 6/12, Step 0/2391, Loss: 30.808914184570312\n",
            "Epoch 6/12, Step 100/2391, Loss: 53.3726806640625\n",
            "Epoch 6/12, Step 200/2391, Loss: 102.69424438476562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rHmvFMp1NEsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44086ce7-3d11-45df-bb2d-52c932067e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-48f45f5afd35>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Xte = torch.load(test_file)  # Xte shape: (M, C, 4), where M is the number of test instances, C is context window size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'note_predictions.pt'.\n"
          ]
        }
      ],
      "source": [
        "# --- Predicting on Test Data ---\n",
        "\n",
        "def predict_on_test_data(model, test_file, context_window=64):\n",
        "    # Load the test data (Xte)\n",
        "    Xte = torch.load(test_file)  # Xte shape: (M, C, 4), where M is the number of test instances, C is context window size\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients for inference\n",
        "        for i in range(Xte.shape[0]):  # Loop through each test instance\n",
        "            test_instance = Xte[i:i + 1, :, :]  # Shape: (1, C, 4)\n",
        "            output = model(test_instance.float())  # Predict distribution parameters (shape: (1, 134))\n",
        "\n",
        "            predictions.append(output.squeeze(0))  # Remove the batch dimension (1, 134) -> (134)\n",
        "\n",
        "    # Convert list of predictions to a tensor of shape (M, 134)\n",
        "    predictions_tensor = torch.stack(predictions)  # Shape: (M, 134)\n",
        "\n",
        "    # Save the predictions to a file\n",
        "    torch.save(predictions_tensor, \"note_predictions.pt\")\n",
        "    print(\"Predictions saved to 'note_predictions.pt'.\")\n",
        "\n",
        "# Example usage:\n",
        "test_file = \"/content/sample_data/test.pt\"  # Path to your test data file\n",
        "predict_on_test_data(model, test_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) To ensure an adequate and diverse dataset, we extracted multiple overlapping context windows from each song with the following considerations:\n",
        "\n",
        "I used Multiple Instances Per Song to better capture the variations in musical patterns. This approach avoided under-utilizing the available data. I used a stride of 4 to avoid overlapping windows, increasing the effective dataset size.I limited max_samples_per_song to ensure that no single song dominated the dataset due to repeated patterns.\n",
        "Random Sampling: Random sampling of context windows ensured diversity in the extracted data, making the dataset more robust."
      ],
      "metadata": {
        "id": "i0rdK346konR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5a) Input: (Batch, Context_Window, 4)\n",
        "        |\n",
        "    LSTM (Input=4, Hidden=128, Layers=2)\n",
        "        |\n",
        "    Fully Connected Layer (Input=128, Output=134)\n",
        "        |\n",
        "    Outputs: [μ_t, σ_t, μ_d, σ_d, log(π0)...log(π127), μ_v, σ_v]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "5b) Design Choices:\n",
        "\n",
        "**LSTM Layers:** We used a 2-layer LSTM to capture temporal dependencies in the sequence of notes. LSTM is ideal for handling sequential data such as music.\n",
        "\n",
        "**Fully Connected Layer:** The FC layer outputs the parameters of the probability distributions, ensuring alignment with the task’s requirements.\n",
        "\n",
        "**Hyperparameters**: We used a hidden size of 128 to balance model capacity and computational efficiency."
      ],
      "metadata": {
        "id": "ik7IM0gFk1xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6)\n",
        "\n",
        " **Partitioning:**\n",
        "\n",
        "Training Set: 80% of the data.\n",
        "Validation Set: 20% of the data, stratified to ensure diversity.\n",
        "\n",
        "**Loss Function:**\n",
        "\n",
        "Continuous Attributes (t, d, v): Negative Log-Likelihood (NLL) loss for normal distributions.\n",
        "Categorical Attribute (n): Cross-entropy loss.\n",
        "\n",
        "**Optimizer:**\n",
        "\n",
        "Adam Optimizer: Used for its adaptive learning rates.\n",
        "Learning Rate: Set to 0.01 based on initial experiments.\n",
        "\n",
        "**Hyperparameters:**\n",
        "\n",
        "**Batch Size**: 32\n",
        "**Epochs** : 10\n",
        "\n",
        "**Regularization**: L2 weight decay was considered but found unnecessary due to no overfitting in initial runs.\n",
        "\n",
        "No data augmentation was used since music patterns are inherently structured.\n",
        "Implementation:\n"
      ],
      "metadata": {
        "id": "uds48w57kqaS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgV9GzqvwaV9MlQthQ+0q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}